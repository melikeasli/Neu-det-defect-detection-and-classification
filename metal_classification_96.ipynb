{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CLASSIFICATION\n",
        "First, we add all the libraries we use in the project.\n",
        "* PyTorch (torch): This will handle all learning and calculation tasks.\n",
        "* Torchvision: An add-on package used for processing, cropping, and converting images.\n",
        "* NumPy & Pandas: Math tools that allow us to manage data in the form of tables and lists of numbers.\n",
        "* Matplotlib & Seaborn: Drawing tools that will show us the results with graphs and color tables.\n",
        "* OS & Zipfile: Logistic elements that will navigate the computer's file system and open the compressed data file."
      ],
      "metadata": {
        "id": "wfw-S2JjGIjH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "import torchvision.transforms as transforms\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "import zipfile\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import time\n",
        "import copy\n",
        "from tqdm.auto import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "cBG5XgvBg1AQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We fix the random number generation (called a \"seed\") so that the code produces the same results every time it runs. We also check if your computer has a powerful graphics card (GPU), and if so, we select it for much faster processing."
      ],
      "metadata": {
        "id": "t8RWMLl5GpGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed=42):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    print(f\"✓ Random seed: {seed}\")\n",
        "\n",
        "SEED = 42\n",
        "set_seed(SEED)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Device: {device}')\n"
      ],
      "metadata": {
        "id": "zmB-WiJUg6AW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing and Introducing the Dataset\n",
        "* Unzip: First, extract the compressed neu-surface.zip file to a folder.\n",
        "* Dataset Class: Create a custom structure called NEUSurfaceDefectDataset. This structure provides the model with the information \"Here's the image, and here's the label (which error it is)\" each time.\n",
        "* Folder Reading: The load_dataset_from_folders function looks at the folder names (e.g., scratches, patches) and converts these names into numbers (0, 1, 2...) that the model can understand. In other words, it creates a map."
      ],
      "metadata": {
        "id": "uJ9HfwM9IOAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path = '/content/neu-surface.zip'\n",
        "extract_path = '/content/neu_dataset'\n",
        "\n",
        "if not os.path.exists(extract_path):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "\n",
        "dataset_base = os.path.join(extract_path, 'NEU-DET')\n",
        "\n",
        "class NEUSurfaceDefectDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "def load_dataset_from_folders(base_path, split='train'):\n",
        "    image_paths = []\n",
        "    labels = []\n",
        "    split_path = os.path.join(base_path, split, 'images')\n",
        "\n",
        "    if not os.path.exists(split_path):\n",
        "        return None, None, None\n",
        "\n",
        "    class_folders = sorted([d for d in os.listdir(split_path)\n",
        "                           if os.path.isdir(os.path.join(split_path, d))])\n",
        "\n",
        "    class_names = class_folders\n",
        "    class_to_idx = {class_name: idx for idx, class_name in enumerate(class_names)}\n",
        "\n",
        "    for class_name in class_folders:\n",
        "        class_path = os.path.join(split_path, class_name)\n",
        "        images = [f for f in os.listdir(class_path)\n",
        "                 if f.endswith(('.jpg', '.png', '.bmp'))]\n",
        "\n",
        "        for img_file in images:\n",
        "            img_path = os.path.join(class_path, img_file)\n",
        "            image_paths.append(img_path)\n",
        "            labels.append(class_to_idx[class_name])\n",
        "\n",
        "    return image_paths, labels, class_names\n",
        "\n",
        "train_paths, train_labels, class_names = load_dataset_from_folders(dataset_base, 'train')\n",
        "val_paths, val_labels, _ = load_dataset_from_folders(dataset_base, 'validation')\n",
        "\n",
        "print(f\"Classes: {class_names}\")\n",
        "print(f\"Train: {len(train_paths)} | Val: {len(val_paths)}\")"
      ],
      "metadata": {
        "id": "tbPT7mlOg8uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation\n",
        "To prevent the model from memorizing, we apply the following operations to the images in the transforms block: We randomly rotate the image, take a mirror image, or slightly flip it. We randomly change its brightness, contrast, or color saturation. We bend the image as if it were viewed sideways or add random black dots (RandomErasing) to it."
      ],
      "metadata": {
        "id": "vvv9U3eeISF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 224\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=30),\n",
        "    transforms.RandomPerspective(distortion_scale=0.3, p=0.5),\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2, hue=0.1),\n",
        "    transforms.RandomGrayscale(p=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomErasing(p=0.3, scale=(0.02, 0.15)),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "KUFMBjfhhBEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Solving Class Imbalance - Weighted Sampler\n",
        "Some errors in the dataset (e.g., inclusion and pitted_surface) are harder to distinguish than others. Here, we set up a Sampler and tell the model: \"When drawing questions from the bag, draw twice as many questions from those two topics you struggle with (inclusion, pitted_surface).\" In this way, the model closes the gap by being exposed to the topics it struggles with more."
      ],
      "metadata": {
        "id": "MPbJ-YBhI7O_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_weighted_sampler(labels, class_names):\n",
        "    class_counts = {}\n",
        "    for label in labels:\n",
        "        class_counts[label] = class_counts.get(label, 0) + 1\n",
        "\n",
        "    weights = []\n",
        "    for label in labels:\n",
        "        class_name = class_names[label]\n",
        "\n",
        "        if class_name in ['inclusion', 'pitted_surface']:\n",
        "            weight = 2.0 / class_counts[label]\n",
        "        else:\n",
        "            weight = 1.0 / class_counts[label]\n",
        "\n",
        "        weights.append(weight)\n",
        "\n",
        "    sampler = WeightedRandomSampler(\n",
        "        weights=weights,\n",
        "        num_samples=len(weights),\n",
        "        replacement=True\n",
        "    )\n",
        "\n",
        "    return sampler\n",
        "\n",
        "train_sampler = create_weighted_sampler(train_labels, class_names)\n",
        "\n",
        "print(\"\\n✓ WEIGHTED SAMPLING ACTIVE\")\n",
        "print(\"  - INCLUSION: 2x more frequent\")\n",
        "print(\"  - PITTED_SURFACE: 2x more frequent\")"
      ],
      "metadata": {
        "id": "aFCVdLSmhDcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loaders\n",
        "Batch Size (32): We cannot give the model 1000 images at the same time. Therefore, here we say, \"Take 32 images at a time, work on them, then move on to the next 32.\"\n",
        "Train Loader: Carries the training data. Here we use the Sampler we prepared earlier.\n",
        "Validation Loader: Here we do not mix the images and we do not use Sampler; we just give them in order and ask, \"Did you know this?\""
      ],
      "metadata": {
        "id": "A34wRTqkKORQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = NEUSurfaceDefectDataset(\n",
        "    image_paths=train_paths,\n",
        "    labels=train_labels,\n",
        "    transform=train_transform\n",
        ")\n",
        "\n",
        "val_dataset = NEUSurfaceDefectDataset(\n",
        "    image_paths=val_paths,\n",
        "    labels=val_labels,\n",
        "    transform=val_transform\n",
        ")\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 0\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    sampler=train_sampler,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True if torch.cuda.is_available() else False,\n",
        "    persistent_workers=False\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True if torch.cuda.is_available() else False,\n",
        "    persistent_workers=False\n",
        ")\n",
        "\n",
        "print(f\"\\n✓ Train batches: {len(train_loader)}\")\n",
        "print(f\"✓ Val batches: {len(val_loader)}\")\n"
      ],
      "metadata": {
        "id": "fOe_s2tkhJEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Architecture\n",
        "Instead of using a ready-made model (ResNet, etc.), a custom model (Create_cnn_module) was built from scratch here.\n",
        "* Conv2d: Filters that scan the edges, corners, and textures in the image. It learns simple lines in the first layers and complex metal textures in later layers.\n",
        "* BatchNormalization: Keeps the training balanced by preventing the numbers from becoming too large or too small during learning.\n",
        "* ReLU (Decision Maker): Filters the incoming information by saying \"This is important, pass\" or \"This is unnecessary, reset\".\n",
        "* Classifier: Finally, it is the decision-making mechanism that looks at all the extracted features and says \"This is 90% likely to be scratches\"."
      ],
      "metadata": {
        "id": "lIHsURziKYMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Create_cnn_module(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=6):\n",
        "        super(Create_cnn_module, self).__init__()\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.features = nn.Sequential(\n",
        "            # Block 1\n",
        "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
        "\n",
        "            # Block 2\n",
        "            nn.Conv2d(64, 128, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
        "\n",
        "            # Block 3\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # Block 4\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
        "        )\n",
        "\n",
        "        # Adaptive pooling\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
        "\n",
        "        # Classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.4),\n",
        "            nn.Linear(256 * 7 * 7, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Dropout(p=0.4),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)"
      ],
      "metadata": {
        "id": "jyiII84BmxG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we define what happens when the model makes a mistake:\n",
        "* Focal Loss: Unlike the standard penalty system, this system ignores easy examples that the model already knows and focuses on difficult examples that it doesn't know. In other words, the model cannot take the easy way out.\n",
        "* AdamW: An algorithm that allows the model to learn from its mistakes and update itself.\n",
        "* Scheduler: If the model's learning stalls (for example, if it doesn't improve for 5 rounds), it slows down the \"learning rate\" to allow for more precise and fine-tuning."
      ],
      "metadata": {
        "id": "mSzZmvgnLKGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=1, gamma=2, label_smoothing=0.1):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.label_smoothing = label_smoothing\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = nn.functional.cross_entropy(\n",
        "            inputs, targets, reduction='none',\n",
        "            label_smoothing=self.label_smoothing\n",
        "        )\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss\n",
        "        return focal_loss.mean()\n",
        "\n",
        "criterion = FocalLoss(alpha=1, gamma=2, label_smoothing=0.1)\n",
        "\n",
        "LEARNING_RATE = 0.0001\n",
        "WEIGHT_DECAY = 5e-4\n",
        "\n",
        "optimizer = optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=LEARNING_RATE,\n",
        "    weight_decay=WEIGHT_DECAY\n",
        ")\n",
        "\n",
        "scheduler = lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='min',\n",
        "    factor=0.5,\n",
        "    patience=5,\n",
        "    min_lr=1e-7\n",
        ")\n",
        "\n",
        "print(f\"\\n✓ Loss: FocalLoss (gamma=2, smoothing=0.1)\")\n",
        "print(f\"✓ Optimizer: AdamW (lr={LEARNING_RATE}, wd={WEIGHT_DECAY})\")"
      ],
      "metadata": {
        "id": "WKE31g5ehelQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section contains the functions that define how the training will be conducted:\n",
        "* train_one_epoch: This is where the model enters the training phase. It makes predictions, identifies its mistakes, and corrects itself.\n",
        "* validate: This is where the model takes the test. It only makes predictions; it doesn't correct itself.\n",
        "* train_model: This is the main loop that manages the entire process. It records the grades at the end of each cycle. It then records the best result."
      ],
      "metadata": {
        "id": "-YcEHYiXLVWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    pbar = tqdm(dataloader, desc='Training', leave=False)\n",
        "\n",
        "    for inputs, labels in pbar:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "        total_samples += inputs.size(0)\n",
        "\n",
        "        pbar.set_postfix({\n",
        "            'loss': f'{loss.item():.4f}',\n",
        "            'acc': f'{running_corrects.double() / total_samples:.4f}'\n",
        "        })\n",
        "\n",
        "    epoch_loss = running_loss / total_samples\n",
        "    epoch_acc = running_corrects.double() / total_samples\n",
        "\n",
        "    return epoch_loss, epoch_acc.item()\n",
        "\n",
        "def validate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    pbar = tqdm(dataloader, desc='Validation', leave=False)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in pbar:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "            total_samples += inputs.size(0)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            pbar.set_postfix({\n",
        "                'loss': f'{loss.item():.4f}',\n",
        "                'acc': f'{running_corrects.double() / total_samples:.4f}'\n",
        "            })\n",
        "\n",
        "    epoch_loss = running_loss / total_samples\n",
        "    epoch_acc = running_corrects.double() / total_samples\n",
        "\n",
        "    return epoch_loss, epoch_acc.item(), all_preds, all_labels\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer,\n",
        "                scheduler, num_epochs, device, early_stopping_patience=15):\n",
        "\n",
        "    since = time.time()\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    best_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'train_acc': [],\n",
        "        'val_loss': [],\n",
        "        'val_acc': []\n",
        "    }\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 70)\n",
        "\n",
        "        train_loss, train_acc = train_one_epoch(\n",
        "            model, train_loader, criterion, optimizer, device\n",
        "        )\n",
        "\n",
        "        val_loss, val_acc, _, _ = validate(\n",
        "            model, val_loader, criterion, device\n",
        "        )\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "\n",
        "        print(f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}')\n",
        "        print(f'Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}')\n",
        "        current_lr = optimizer.param_groups[0]['lr']\n",
        "        print(f'LR: {current_lr:.6f}')\n",
        "\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            best_loss = val_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            epochs_no_improve = 0\n",
        "            print(f'✓ Best model updated! (Val Acc: {val_acc:.4f})')\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            print(f'⚠ {epochs_no_improve}/{early_stopping_patience} - No improvement')\n",
        "\n",
        "        if epochs_no_improve >= early_stopping_patience:\n",
        "            print(f'\\nEarly Stopping at epoch {epoch+1}')\n",
        "            break\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'\\nTraining completed: {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    print(f'Best Val Accuracy: {best_acc:.4f}')\n",
        "    print(f'Best Val Loss: {best_loss:.4f}')\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, history\n"
      ],
      "metadata": {
        "id": "Py07fsUqhiY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 50\n",
        "EARLY_STOPPING_PATIENCE = 10\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"TRAINING STARTED\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "trained_model, history = train_model(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    device=device,\n",
        "    early_stopping_patience=EARLY_STOPPING_PATIENCE\n",
        ")\n"
      ],
      "metadata": {
        "id": "yZV-Ccu3hpSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis of Results\n",
        "* Confusion Matrix: Draws a 6x6 table. This table tells us: \"How many times did the model correctly identify an error that was actually a 'Patch', and how many times did it mistakenly identify it as a 'Scratch'?\"\n",
        "* Classification Report: Lists the success percentage (Precision, Recall, F1-Score) separately for each error type. For example, if you see Crazing: 1.00 in the report, it means the model identified that error 100% correctly."
      ],
      "metadata": {
        "id": "IGdLJrMoMJlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss, val_acc, val_preds, val_labels = validate(\n",
        "    trained_model, val_loader, criterion, device\n",
        ")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"FINAL RESULTS\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Final Val Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
        "print(f\"Final Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(val_labels, val_preds)\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"CONFUSION MATRIX\")\n",
        "print(f\"{'='*70}\")\n",
        "print(cm)\n",
        "\n",
        "# Classification Report\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"CLASSIFICATION REPORT\")\n",
        "print(f\"{'='*70}\")\n",
        "report = classification_report(\n",
        "    val_labels,\n",
        "    val_preds,\n",
        "    target_names=[c.upper() for c in class_names],\n",
        "    digits=4\n",
        ")\n",
        "print(report)\n",
        "\n",
        "# Per-class accuracy\n",
        "per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"PER-CLASS ACCURACY\")\n",
        "print(f\"{'='*70}\")\n",
        "for i, class_name in enumerate(class_names):\n",
        "    print(f\"{class_name.upper()}: {per_class_acc[i]:.4f} ({per_class_acc[i]*100:.2f}%)\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"✓✓✓ TRAINING COMPLETED SUCCESSFULLY ✓✓✓\")\n",
        "print(f\"{'='*70}\")"
      ],
      "metadata": {
        "id": "c-C2Ffg3hsmd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}